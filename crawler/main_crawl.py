import os
import time
import logging
from datetime import datetime

# --- ê° ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬ import ---
from services.fmkorea.fm_best_crawl import FmkoreaBest
from services.dcinside.dc_best_crawl import DcinsideBest
from services.ruliweb.ruliweb_best_crawl import RuliwebBest
from services.theqoo.theqoo_hot_crawl import TheqooHot

# ë¡œê·¸ ì„¤ì •
LOG_DIR = os.path.join(os.path.dirname(__file__), "logs")
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = os.path.join(LOG_DIR, f"crawl_{datetime.now():%Y%m%d}.log")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filename, encoding="utf-8"),
        logging.StreamHandler(),  # ì½˜ì†” ì¶œë ¥ë„ ê°™ì´
    ],
)

logger = logging.getLogger(__name__)

# í¬ë¡¤ëŸ¬ ì‹¤í–‰ í•¨ìˆ˜
def run_crawler(crawler_cls, name):
    try:
        logger.info(f"ğŸš€ {name} í¬ë¡¤ë§ ì‹œì‘")
        crawler = crawler_cls()
        crawler.start()
        logger.info(f"âœ… {name} í¬ë¡¤ë§ ì™„ë£Œ\n")
    except Exception as e:
        logger.exception(f"âŒ {name} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

# ë©”ì¸ ì‹¤í–‰
def main():
    logger.info("=" * 50)
    logger.info("ğŸ•·ï¸ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")

    crawlers = [
        ("FMKOREA", FmkoreaBest),
        ("DCINSIDE", DcinsideBest),
        ("RULIWEB", RuliwebBest),
        ("THEQOO", TheqooHot),
    ]

    for name, crawler_cls in crawlers:
        run_crawler(crawler_cls, name)
        time.sleep(3)  # ì‚¬ì´íŠ¸ ê°„ ìš”ì²­ ê°„ê²©

    logger.info("ğŸ¯ ëª¨ë“  ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì™„ë£Œ")
    logger.info("=" * 50)

if __name__ == "__main__":
    main()
